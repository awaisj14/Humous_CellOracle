 #!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Feb 22 16:44:52 2023

@author: javed
"""

# 0. Import

import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import seaborn as sns

import celloracle as co
co.__version__
# visualization settings
%config InlineBackend.figure_format = 'retina'
%matplotlib inline

plt.rcParams['figure.figsize'] = [6, 4.5]
plt.rcParams["savefig.dpi"] = 300
save_folder = "figures"
os.makedirs(save_folder, exist_ok=True)

adata = sc.read_h5ad("Final_celloracle_v2.h5ad")
print(f"Cell number is :{adata.shape[0]}")
print(f"Gene number is :{adata.shape[1]}")
# Random downsampling into 30K cells if the anndata object include more than 30 K cells.
n_cells_downsample = 30000
if adata.shape[0] > n_cells_downsample:
    # Let's dowmsample into 30K cells
    sc.pp.subsample(adata, n_obs=n_cells_downsample, random_state=123)
print(f"Cell number is :{adata.shape[0]}")

df = pd.read_parquet("base_GRN_dataframe_filtered.parquet")   

base_GRN = df

# Check data
base_GRN.head()

# Instantiate Oracle object
oracle = co.Oracle()


# Check data in anndata
print("Metadata columns :", list(adata.obs.columns))
print("Dimensional reduction: ", list(adata.obsm.keys()))


# In this notebook, we use the unscaled mRNA count for the nput of Oracle object.
adata.X = adata.layers["raw_count"].copy()

# Instantiate Oracle object.
oracle.import_anndata_as_raw_count(adata=adata,
                                   cluster_column_name="celltype",
                                   embedding_name="X_draw_graph_fa")
# You can load TF info dataframe with the following code.
oracle.import_TF_data(TF_info_matrix=base_GRN)

# Alternatively, if you saved the informmation as a dictionary, you can use the code below.
# oracle.import_TF_data(TFdict=TFinfo_dictionary)

#Database was downloaded from: https://cdn.netbiol.org/tflink/download_files/TFLink_Mus_musculus_interactions_All_GMT_proteinName_v1.0.gmt


input_gmt = "/Users/Javed/Documents/Humous/TFLink_Homo_sapiens_interactions_All_GMT_proteinName_v1.0.gmt"
output_csv = "TFLink_Homo_sapiens_interactions_All_GMT_proteinName_v1.0.csv"


# Initialize a list to hold the TF and Target_genes pairs
data = []

# Read and process the GMT file
with open(input_gmt, 'r') as file:
    for line_number, line in enumerate(file, start=1):
        # Strip newline characters and split by tab
        parts = line.strip().split('\t')
        
        # Check if the line has at least three columns (TF, Description, at least one gene)
        if len(parts) < 3:
            print(f"Warning: Line {line_number} in {input_gmt} does not have enough columns. Skipping.")
            continue
        
        tf = parts[0]  # GeneSetName as TF
        # description = parts[1]  # Description (ignored)
        target_genes = parts[2:]  # List of Target_genes
        
        # Append each TF and its Target_genes to the data list
        for gene in target_genes:
            # Optional: Skip empty gene entries
            if gene.strip() == "":
                continue
            data.append({'TF': tf, 'Target_genes': gene})

# Create a DataFrame from the data list
df = pd.DataFrame(data)

# Optional: Remove duplicate entries if any
df.drop_duplicates(inplace=True)

# Save the DataFrame to a CSV file
df.to_csv(output_csv, index=False)

print(f"DataFrame with TF and Target_genes has been saved to {output_csv}")


Paul_15_data = df

# Make dictionary: dictionary key is TF and dictionary value is list of target genes.
TF_to_TG_dictionary = {}

for TF, TGs in zip(Paul_15_data.TF, Paul_15_data.Target_genes):
    # convert target gene to list
    TG_list = TGs.replace(" ", "").split(",")
    # store target gene list in a dictionary
    TF_to_TG_dictionary[TF] = TG_list

# We invert the dictionary above using a utility function in celloracle.
TG_to_TF_dictionary = co.utility.inverse_dictionary(TF_to_TG_dictionary)


# Add TF information
oracle.addTFinfo_dictionary(TG_to_TF_dictionary)
# Perform PCA
oracle.perform_PCA()

# Select important PCs
plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])
n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]
plt.axvline(n_comps, c="k")
plt.show()
print(n_comps)
n_comps = min(n_comps, 50)


n_cell = oracle.adata.shape[0]
print(f"cell number is :{n_cell}")
k = int(0.025*n_cell)
print(f"Auto-selected k is :{k}")
oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,
                      b_maxl=k*4, n_jobs=4)

# Save oracle object.
oracle.to_hdf5("Paul_15_data_v2.celloracle.oracle")
# Load file.
oracle = co.load_hdf5("Paul_15_data_v2.celloracle.oracle")


# Check clustering data
sc.pl.draw_graph(oracle.adata, color="celltype")


# Calculate GRN for each population in "louvain_annot" clustering unit.
# This step may take some time.(~30 minutes)
links = oracle.get_links(cluster_name_for_GRN_unit="celltype", alpha=10,
                         verbose_level=10)
links.links_dict.keys()

# Save Links object.
links.to_hdf5(file_path="links_v2.celloracle.links")



## NETWORK PRE PROCESSING
links = co.load_hdf5("links_v2.celloracle.links")

links.filter_links(p=0.05, weight="coef_abs", threshold_number=10000)

plt.rcParams["figure.figsize"] = [9, 4.5]
links.plot_degree_distributions(plot_model=True,
                                               #save=f"{save_folder}/degree_distribution/",
                                               )
plt.rcParams["figure.figsize"] = [6, 4.5]
# Calculate network scores.
links.get_network_score()
links.merged_score.head()


# Save Links object.
links.to_hdf5(file_path="links_v2.celloracle.links")
# You can load files with the following command.
links = co.load_hdf5(file_path="links_v2.celloracle.links")

# Check cluster name
links.cluster




cluster_name = "RG"
filtered_links_df = links.filtered_links[cluster_name]
filtered_links_df.head()
filtered_links_df.to_csv("/Users/javed/Documents/Human_multiome/Celloracle/GRN_FINAL/RG_GRN_v2.csv")

cluster_name = "IP"
filtered_links_df = links.filtered_links[cluster_name]
filtered_links_df.head()
filtered_links_df.to_csv("/Users/javed/Documents/Human_multiome/Celloracle/GRN_FINAL/IP_GRN_v2.csv")

cluster_name = "N"
filtered_links_df = links.filtered_links[cluster_name]
filtered_links_df.head()
filtered_links_df.to_csv("//Users/javed/Documents/Human_multiome/Celloracle/GRN_FINAL/N_GRN_v2.csv")



# Visualize top n-th genes with high scores.
links.plot_scores_as_rank(cluster="RG", n_gene=30, save=f"{save_folder}/ranked_score")
# Visualize top n-th genes with high scores.
links.plot_scores_as_rank(cluster="IP", n_gene=30, save=f"{save_folder}/ranked_score")
# Visualize top n-th genes with high scores.
links.plot_scores_as_rank(cluster="N", n_gene=30, save=f"{save_folder}/ranked_score")



# Compare GRN score between two clusters
links.plot_score_comparison_2D(value="eigenvector_centrality",
                               cluster1="RG", cluster2="N",
                               percentile=98,
                               save=f"{save_folder}/score_comparison")

# Visualize Gata2 network score dynamics
links.plot_score_per_cluster(goi="JUNB", save=f"{save_folder}/network_score_per_gene/")
# Visualize Cebpa network score dynamics
links.plot_score_per_cluster(goi="JUNB")
cluster_name = "RG"
filtered_links_df = links.filtered_links[cluster_name]
filtered_links_df.head()

filtered_links_df[filtered_links_df.source == "JUNB"]


plt.rcParams["figure.figsize"] = [6, 4.5]
# Plot degree_centrality
plt.subplots_adjust(left=0.15, bottom=0.3)
plt.ylim([0,0.040])
links.plot_score_discributions(values=["degree_centrality_all"],
                               method="boxplot",
                               save=f"{save_folder}",
                              )


# Plot eigenvector_centrality
plt.subplots_adjust(left=0.15, bottom=0.3)
plt.ylim([0, 0.28])
links.plot_score_discributions(values=["eigenvector_centrality"],
                               method="boxplot",
                               save=f"{save_folder}")


plt.subplots_adjust(left=0.15, bottom=0.3)
links.plot_network_entropy_distributions(save=f"{save_folder}")





















